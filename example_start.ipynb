{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "BUFFER = 50\n",
    "MONITOR = \"val_accuracy\"\n",
    "BASE_EPOCHS = 2\n",
    "BASE_PATIENCE = 5\n",
    "MIN_DELTA = .02\n",
    "MONITOR = \"val_accuracy\"\n",
    "LOGS = \"logs\"\n",
    "DIR_OUT = \"kt_out\"\n",
    "PROJECT = \"kt_basics\"\n",
    "FACTOR = 3\n",
    "VALIDATION = .2\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "  batch_size = 64\n",
    "  !pip install keras_tuner\n",
    "  !pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input, LeakyReLU\n",
    "from keras.utils import np_utils\n",
    "import datetime\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential\n",
    "\n",
    "import os, warnings\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.data.experimental import sample_from_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Veggie Classification\n",
    "\n",
    "For this assignment you'll need to classify some images of vegetables. \n",
    "\n",
    "## Parts\n",
    "\n",
    "Please do two separate classifications:\n",
    "<ol>\n",
    "<li> First, create a model from scratch. \n",
    "<li> Use transfer learning to use a pretrained model of your choice, adapted to this data. \n",
    "</ol>\n",
    "\n",
    "There won't be an explicit evaluation of accuracy, but you should take some steps to make each model as accurate as you reasonably can, any tuning option is fair game. Along with that, please structure it into a notebook that is well structured and clear that explains what you did and found. Think about:\n",
    "<ul>\n",
    "<li> Sections and headings. \n",
    "<li> A description of the approach taken (e.g. what did you do to determine size, tune, evaluate, etc...)\n",
    "<li> Visualization of some important things such as a confusion matrix and maybe some images. \n",
    "<li> Results, mainly focused on the scoring of the test data. \n",
    "</ul>\n",
    "\n",
    "The descriptions and explainations should highlight the choices you made and why you made them. Figure up to about a page or so worth of text total, explain what happened but don't write an essay. \n",
    "\n",
    "## Deliverables\n",
    "\n",
    "Please sumbmit a link to your github, where everyhting is fully run with all the outputs showing on the page. As well, in the notebook please add some kind of switch controlled by a variable that will control if the notebook runs to train the model or to load the model in from weights - so I can download it and click run all, it will load the saved weights, and predict.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The code in the start of this notebook will download and unzip the dataset, and there is also a simple example of creating datasets. You can change the dataset bit to use a different approach if you'd like. The data is already split into train, validation, and test sets. Please treat the separate test set as the final test set, and don't use it for any training or validation. Each folder name is its own label.\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "Marking will be based on the following:\n",
    "<ul>\n",
    "<li> Models are cretaed, tuned, and effective at classifying the data: 40%\n",
    "<li> Descriptions and explanations of the approach taken: 20%\n",
    "<li> Code is well structured and clear: 20%\n",
    "</ul>\n",
    "\n",
    "Overall the marking is pretty simple and direct, walk through the process of predicting the veggies, explain what you did, and show the results. If you do that, it'll get a good mark.\n",
    "\n",
    "### Tips\n",
    "\n",
    "Some hints that may be helpful to keep in mind:\n",
    "<ul>\n",
    "<li> The data is pretty large, so you'll want to use datasets rather than load everything into memory. The Keras docs have a few examples of different ways to load image data, our examples showed image generators and the image from directory datasets.  \n",
    "<li> Be careful of batch size, you may hit the colab limits. \n",
    "<li> You'll want to use checkpoints so you can let it train and pick up where you left off.\n",
    "<li> When developing, using a smaller dataset sample is a good idea. These weights could also be saved and loaded to jump start training on the full data. \n",
    "<li>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Unzip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_custom(current, total, width=80):\n",
    "    print(\"Downloading: %d%% [%d / %d] bytes\" % (current / total * 100, current, total))\n",
    "import wget\n",
    "import zipfile\n",
    "zip_name = \"train.zip\"\n",
    "\n",
    "url = \"https://jrssbcrsefilesnait.blob.core.windows.net/3950data1/vegetable_image_dataset.zip\"\n",
    "\n",
    "if not os.path.exists(zip_name):\n",
    "    wget.download(url, zip_name, bar=bar_custom)\n",
    "\n",
    "with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15000 files belonging to 15 classes.\n",
      "Found 3000 files belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate Datasets - you can change this if desired\n",
    "# ENSURE FILE PATHS MATCH CORRECTLY\n",
    "IMAGE_SIZE=(224,224)\n",
    "train_dir='Vegetable Images/train'\n",
    "val_dir='Vegetable Images/validation'\n",
    "\n",
    "# Load training data\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size = IMAGE_SIZE,\n",
    "    batch_size = None,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size = IMAGE_SIZE,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset element_spec=(TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(15,), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "train_ds_sample = train_ds.take(5000)\n",
    "print(train_ds_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(15,), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (224, 224, 3) for input KerasTensor(type_spec=TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name='rescaling_input'), name='rescaling_input', description=\"created by layer 'rescaling_input'\"), but it was called on an input with incompatible shape (None, 224, 224, 3).\n"
     ]
    }
   ],
   "source": [
    "TPAIN = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "train_ds_sample = train_ds_sample.map(lambda x, y: (rescale(x), y))\n",
    "train_ds_sample = train_ds_sample.batch(batch_size)\n",
    "train_ds_sample = train_ds_sample.prefetch(buffer_size=TPAIN)\n",
    "\n",
    "val_ds = val_ds.map(lambda x, y: (rescale(x), y))\n",
    "val_ds = val_ds.prefetch(buffer_size=TPAIN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping = tf.keras.callbacks.EarlyStopping(monitor=MONITOR, patience=BASE_PATIENCE, mode=\"max\", restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "#         model.add(layers.Conv2D(hp.Int(\"kernel_L\"+str(i), min_value=32, max_value=512, step=16), (3, 3), input_shape=(224, 224, 3), padding=\"same\"))\n",
    "#         model.add(layers.LeakyReLU())\n",
    "#         model.add(layers.MaxPooling2D())\n",
    "    \n",
    "#     model.add(Flatten())\n",
    "#     model.add(layers.Dense(64, activation=\"relu\"))\n",
    "#     model.add(layers.Dense(15, activation=\"sigmoid\"))\n",
    "\n",
    "#     hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "#     model.compile(\n",
    "#         optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "#         loss=\"categorical_crossentropy\",\n",
    "#         metrics=[\"accuracy\"],\n",
    "#     )\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tuner = kt.BayesianOptimization(build_model,\n",
    "#                         objective=MONITOR,\n",
    "#                         max_trials=5,\n",
    "#                         directory=DIR_OUT+\"/\"+file_time,\n",
    "#                         project_name=PROJECT,\n",
    "#                         overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = kt.Hyperband(hypermodel = model_builder2,\n",
    "#                      objective=MONITOR,\n",
    "#                      max_epochs=BASE_EPOCHS,\n",
    "#                      factor=3,\n",
    "#                      directory=DIR_OUT,\n",
    "#                      project_name=PROJECT, \n",
    "#                      overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 02s]\n",
      "\n",
      "Best val_accuracy So Far: 0.7633333206176758\n",
      "Total elapsed time: 00h 01m 09s\n",
      "\n",
      "Search: Running Trial #4\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "3                 |4                 |num_layers\n",
      "304               |176               |kernel_L0\n",
      "304               |64                |kernel_L1\n",
      "144               |336               |kernel_L2\n",
      "0.001             |0.001             |learning_rate\n",
      "352               |32                |kernel_L3\n",
      "96                |None              |kernel_L4\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 266, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 231, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\dlee2\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n",
      "\n",
      "Detected at node 'gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "      app.start()\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "      self.io_loop.start()\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "      self._run_once()\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "      handle._run()\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "      await result\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n",
      "      res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "      return runner(coro)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "      if (await self.run_code(code, result,  async_=asy)):\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"C:\\Users\\dlee2\\AppData\\Local\\Temp\\ipykernel_36292\\2310962767.py\", line 2, in <module>\n",
      "      tuner.search(train_ds_sample, epochs=BASE_EPOCHS, validation_data=val_ds, callbacks=[stopping])\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 226, in search\n",
      "      self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 266, in _try_run_and_update_trial\n",
      "      self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 231, in _run_and_update_trial\n",
      "      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n",
      "      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n",
      "      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n",
      "      return model.fit(*args, **kwargs)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n",
      "      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n",
      "      grads_and_vars = self._compute_gradients(\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n",
      "      grads_and_vars = self._get_gradients(\n",
      "    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n",
      "      grads = tape.gradient(loss, var_list, grad_loss)\n",
      "Node: 'gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropInput'\n",
      "OOM when allocating tensor with shape[32,304,56,56] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropInput}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      " [Op:__inference_train_function_20977]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 266, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 231, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n    return model.fit(*args, **kwargs)\n  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\dlee2\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n\nDetected at node 'gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\dlee2\\AppData\\Local\\Temp\\ipykernel_36292\\2310962767.py\", line 2, in <module>\n      tuner.search(train_ds_sample, epochs=BASE_EPOCHS, validation_data=val_ds, callbacks=[stopping])\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 226, in search\n      self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 266, in _try_run_and_update_trial\n      self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 231, in _run_and_update_trial\n      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n      return model.fit(*args, **kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropInput'\nOOM when allocating tensor with shape[32,304,56,56] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_20977]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36292\\2310962767.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get Results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBASE_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Get the optimal hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbest_hps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36mon_trial_end\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTrial\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \"\"\"\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m         \u001b[1;31m# Display needs the updated trial scored by the Oracle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\oracle.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mLOCKS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthread_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mret_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mneed_acquire\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\oracle.py\u001b[0m in \u001b[0;36mend_trial\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_order\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_consecutive_failures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\oracle.py\u001b[0m in \u001b[0;36m_check_consecutive_failures\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[0mconsecutive_failures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconsecutive_failures\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_consecutive_failed_trials\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m                 raise RuntimeError(\n\u001b[0m\u001b[0;32m    387\u001b[0m                     \u001b[1;34m\"Number of consecutive failures excceeded the limit \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                     \u001b[1;34mf\"of {self.max_consecutive_failed_trials}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 266, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 231, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n    return model.fit(*args, **kwargs)\n  File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\dlee2\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n\nDetected at node 'gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\dlee2\\AppData\\Local\\Temp\\ipykernel_36292\\2310962767.py\", line 2, in <module>\n      tuner.search(train_ds_sample, epochs=BASE_EPOCHS, validation_data=val_ds, callbacks=[stopping])\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 226, in search\n      self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 266, in _try_run_and_update_trial\n      self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 231, in _run_and_update_trial\n      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n      return model.fit(*args, **kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"c:\\Users\\dlee2\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropInput'\nOOM when allocating tensor with shape[32,304,56,56] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_20977]\n"
     ]
    }
   ],
   "source": [
    "# # Get Results\n",
    "# tuner.search(train_ds_sample, epochs=BASE_EPOCHS, validation_data=val_ds, callbacks=[stopping])\n",
    "\n",
    "# # Get the optimal hyperparameters\n",
    "# best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# # Get the best model\n",
    "# best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build best model\n",
    "# best_model.build(input_shape=(None, 224,224,3))\n",
    "# best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to plot loss\n",
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "\n",
    "def plot_acc(history):\n",
    "  plt.plot(history.history['accuracy'], label='accuracy')\n",
    "  plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Model, No Tuning\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "train_log = model.fit(train_ds, epochs=BASE_EPOCHS, verbose=1, callbacks=[stopping], validation_data=val_ds)\n",
    "\n",
    "plot_loss(train_log)\n",
    "plot_acc(train_log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Best Models and Illustrate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 files belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir='Vegetable Images/test'\n",
    "test_ds = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size = IMAGE_SIZE,\n",
    "    batch_size = batch_size,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3950",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
